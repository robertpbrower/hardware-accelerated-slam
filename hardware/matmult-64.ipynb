{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matrix Multiplication\n",
    "\n",
    "This notebook exemplies the use of a hardware overlay to accelerate a floating-point matrix multiplication.\n",
    "The overlay implements the matrix product $\\mathbf{C} = \\mathbf{A}\\mathbf{B} $, \n",
    "where $\\mathbf{A}$, $\\mathbf{B}$, and $\\mathbf{C}$ are $64 \\times 64$ floating-point matrices.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pynq import (allocate, Overlay)\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the overlay\n",
    "\n",
    "Program the FPGA and reference the required hardware blocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "ol = Overlay('/home/xilinx/pynq/overlays/matmult/64/matmult.bit')\n",
    "\n",
    "dma = ol.dma\n",
    "mmult_ip = ol.accel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Allocate memory for the DMA transfers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIM = 64\n",
    "in_buffer = allocate(shape=(2, DIM, DIM), dtype=np.float32, cacheable=False)\n",
    "out_buffer = allocate(shape=(DIM, DIM), dtype=np.float32, cacheable=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix multiplication in hardware (PL side)\n",
    "\n",
    "The execution of the algorithm using the hardware kernel includes the roundtrip data transfer (processor to FPGA, and FPGA to processor). Usually, this data transfer constitutes the performance bottleneck."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "CTRL_REG = 0x00\n",
    "AP_START = (1<<0) # bit 0\n",
    "AUTO_RESTART = (1<<7) # bit 7\n",
    "mmult_ip.register_map.k = DIM\n",
    "mmult_ip.register_map.m = DIM\n",
    "mmult_ip.register_map.n = DIM\n",
    "\n",
    "def run_kernel():\n",
    "    dma.sendchannel.transfer(in_buffer)\n",
    "    dma.recvchannel.transfer(out_buffer)\n",
    "    mmult_ip.write(CTRL_REG, (AP_START | AUTO_RESTART))  # initialize the module\n",
    "    dma.sendchannel.wait()\n",
    "    dma.recvchannel.wait()\n",
    "    \n",
    "HW_SIZE = 64\n",
    "    \n",
    "def matmult_driver(A, B):\n",
    "    (a_xSize, a_ySize) = np.shape(A)\n",
    "\n",
    "    (b_xSize, b_ySize) = np.shape(B)\n",
    "\n",
    "    a = np.concatenate((A, np.zeros((a_ySize, HW_SIZE-a_xSize))), axis=1)\n",
    "    a = np.concatenate((a, np.concatenate((np.zeros((HW_SIZE-a_xSize, a_ySize)), \n",
    "                                            np.eye(HW_SIZE-a_ySize , HW_SIZE-a_xSize)), axis=1)), axis=0)\n",
    "    b = np.concatenate((B, np.zeros((b_ySize, HW_SIZE-b_xSize))), axis=1)\n",
    "    b = np.concatenate((b, np.concatenate((np.zeros((HW_SIZE-b_xSize, b_ySize)), \n",
    "                                            np.eye(HW_SIZE-b_ySize , HW_SIZE-b_xSize)), axis=1)), axis=0)\n",
    "\n",
    "#     print(np.shape(a))\n",
    "#     print(np.shape(b))\n",
    "    in_buffer[:] = np.stack((a, b))\n",
    "\n",
    "    run_kernel()\n",
    "    \n",
    "    return out_buffer[:a_xSize, :a_ySize]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create example matrices to evaluate the kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIM = 10\n",
    "\n",
    "A = np.random.rand(DIM, DIM).astype(dtype=np.float32)\n",
    "B = np.random.rand(DIM, DIM).astype(dtype=np.float32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Measure the execution time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.47 ms ± 101 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "AB = matmult_driver(A, B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix multiplication in software (PS side)\n",
    "\n",
    "NumPy is the golden standard against with the hardware implementation is compared. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30.5 µs ± 49.6 ns per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit A @ B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify correctness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array_equal(A @ B, AB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
